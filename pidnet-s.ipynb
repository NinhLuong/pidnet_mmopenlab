{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc00d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:16:21.160007Z",
     "iopub.status.busy": "2023-05-11T10:16:21.159371Z",
     "iopub.status.idle": "2023-05-11T10:19:09.884589Z",
     "shell.execute_reply": "2023-05-11T10:19:09.883300Z"
    },
    "papermill": {
     "duration": 168.736867,
     "end_time": "2023-05-11T10:19:09.887119",
     "exception": false,
     "start_time": "2023-05-11T10:16:21.150252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\r\n",
      "Collecting torch==1.12.0\r\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1837.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m506.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.0) (4.5.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.0.0\r\n",
      "    Uninstalling torch-2.0.0:\r\n",
      "      Successfully uninstalled torch-2.0.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.0+cu113 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0+cu113\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting openmim\r\n",
      "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.28.2)\r\n",
      "Collecting model-index\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (23.0.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.3.3)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (1.5.3)\r\n",
      "Collecting ordered-set\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.4.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.3)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.23.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.15)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.15.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\r\n",
      "Installing collected packages: ordered-set, model-index, openmim\r\n",
      "Successfully installed model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.7.3-py3-none-any.whl (372 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.1/372.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.32.0)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.2.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.6.3)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.5.4.60)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.3.3)\r\n",
      "Collecting addict\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.23.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.11.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (9.5.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.0.7)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.39.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.0.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (21.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.4)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.15.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.7.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\r\n",
      "Collecting mmcv>=2.0.0\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv-2.0.0-cp310-cp310-manylinux1_x86_64.whl (70.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (0.7.3)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (4.5.4.60)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (0.32.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (6.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (21.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (1.23.5)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0) (9.5.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv>=2.0.0) (3.6.3)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv>=2.0.0) (2.2.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv>=2.0.0) (13.3.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv>=2.0.0) (3.0.9)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (1.0.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (1.4.4)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (4.39.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (2.8.2)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.2.0->mmcv>=2.0.0) (2.15.0)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.2.0->mmcv>=2.0.0) (2.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine>=0.2.0->mmcv>=2.0.0) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "!pip install torch==1.12.0 torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install -U openmim\n",
    "# Install mmengine\n",
    "!mim install mmengine\n",
    "# Install MMCV\n",
    "!mim install 'mmcv >= 2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3e6b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:10.043466Z",
     "iopub.status.busy": "2023-05-11T10:19:10.042603Z",
     "iopub.status.idle": "2023-05-11T10:19:28.615194Z",
     "shell.execute_reply": "2023-05-11T10:19:28.614035Z"
    },
    "papermill": {
     "duration": 18.653427,
     "end_time": "2023-05-11T10:19:28.617831",
     "exception": false,
     "start_time": "2023-05-11T10:19:09.964404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmsegmentation'...\r\n",
      "remote: Enumerating objects: 14947, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (525/525), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (348/348), done.\u001b[K\r\n",
      "remote: Total 14947 (delta 192), reused 350 (delta 160), pack-reused 14422\u001b[K\r\n",
      "Receiving objects: 100% (14947/14947), 20.63 MiB | 31.81 MiB/s, done.\r\n",
      "Resolving deltas: 100% (10491/10491), done.\r\n",
      "/kaggle/working/mmsegmentation\n",
      "Using pip 23.0.1 from /opt/conda/lib/python3.10/site-packages/pip (python 3.10)\r\n",
      "Obtaining file:///kaggle/working/mmsegmentation\r\n",
      "  Running command python setup.py egg_info\r\n",
      "  running egg_info\r\n",
      "  creating /tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info\r\n",
      "  writing /tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info/PKG-INFO\r\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info/dependency_links.txt\r\n",
      "  writing requirements to /tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info/requires.txt\r\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info/top_level.txt\r\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "  reading manifest template 'MANIFEST.in'\r\n",
      "  warning: no files found matching 'mmseg/.mim/model-index.yml'\r\n",
      "  warning: no files found matching '*.py' under directory 'mmseg/.mim/configs'\r\n",
      "  warning: no files found matching '*.yaml' under directory 'mmseg/.mim/configs'\r\n",
      "  warning: no files found matching '*.py' under directory 'mmseg/.mim/tools'\r\n",
      "  warning: no files found matching '*.sh' under directory 'mmseg/.mim/tools'\r\n",
      "  adding license file 'LICENSE'\r\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-3w41_p11/mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (3.6.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (1.23.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (21.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (3.7.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (1.9.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (2.8.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (4.39.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (0.11.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (1.0.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (3.0.9)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (9.5.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->mmsegmentation==1.0.0) (0.2.6)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.0.0) (1.16.0)\r\n",
      "Installing collected packages: mmsegmentation\r\n",
      "  Running setup.py develop for mmsegmentation\r\n",
      "    Running command python setup.py develop\r\n",
      "    running develop\r\n",
      "    /opt/conda/lib/python3.10/site-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\r\n",
      "      warnings.warn(\r\n",
      "    /opt/conda/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n",
      "      warnings.warn(\r\n",
      "    running egg_info\r\n",
      "    creating mmsegmentation.egg-info\r\n",
      "    writing mmsegmentation.egg-info/PKG-INFO\r\n",
      "    writing dependency_links to mmsegmentation.egg-info/dependency_links.txt\r\n",
      "    writing requirements to mmsegmentation.egg-info/requires.txt\r\n",
      "    writing top-level names to mmsegmentation.egg-info/top_level.txt\r\n",
      "    writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "    reading manifest template 'MANIFEST.in'\r\n",
      "    adding license file 'LICENSE'\r\n",
      "    writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "    running build_ext\r\n",
      "    Creating /opt/conda/lib/python3.10/site-packages/mmsegmentation.egg-link (link to .)\r\n",
      "    Adding mmsegmentation 1.0.0 to easy-install.pth file\r\n",
      "\r\n",
      "    Installed /kaggle/working/mmsegmentation\r\n",
      "Successfully installed mmsegmentation-1.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/open-mmlab/mmsegmentation.git\n",
    "%cd mmsegmentation\n",
    "!pip install -v -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4754769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:28.778535Z",
     "iopub.status.busy": "2023-05-11T10:19:28.778200Z",
     "iopub.status.idle": "2023-05-11T10:19:30.075004Z",
     "shell.execute_reply": "2023-05-11T10:19:30.073788Z"
    },
    "papermill": {
     "duration": 1.379425,
     "end_time": "2023-05-11T10:19:30.077103",
     "exception": false,
     "start_time": "2023-05-11T10:19:28.697678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df9e9e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:30.237900Z",
     "iopub.status.busy": "2023-05-11T10:19:30.237325Z",
     "iopub.status.idle": "2023-05-11T10:19:30.243881Z",
     "shell.execute_reply": "2023-05-11T10:19:30.242955Z"
    },
    "papermill": {
     "duration": 0.089492,
     "end_time": "2023-05-11T10:19:30.245906",
     "exception": false,
     "start_time": "2023-05-11T10:19:30.156414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv.transforms import BaseTransform, TRANSFORMS\n",
    "\n",
    "@TRANSFORMS.register_module()\n",
    "class ConvertPixel(BaseTransform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transform(self, results: dict) -> dict:\n",
    "        img_seg = results['gt_seg_map']\n",
    "        img_seg[img_seg == 0] = 0\n",
    "        img_seg[img_seg == 255] = 1\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb8eace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:30.405058Z",
     "iopub.status.busy": "2023-05-11T10:19:30.404248Z",
     "iopub.status.idle": "2023-05-11T10:19:30.411473Z",
     "shell.execute_reply": "2023-05-11T10:19:30.410131Z"
    },
    "papermill": {
     "duration": 0.08924,
     "end_time": "2023-05-11T10:19:30.413844",
     "exception": false,
     "start_time": "2023-05-11T10:19:30.324604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/mmsegmentation/mmseg/datasets/isicdataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmsegmentation/mmseg/datasets/isicdataset.py\n",
    "from mmseg.registry import DATASETS\n",
    "from .basesegdataset import BaseSegDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ISICDataset(BaseSegDataset):\n",
    "\n",
    "    METAINFO = dict(\n",
    "        classes=('background', 'mask'),\n",
    "        palette=[[0, 0, 0], [255, 255, 255]])\n",
    "\n",
    "    def __init__(self,\n",
    "                 img_suffix='.jpg',\n",
    "                 seg_map_suffix='_segmentation.png',\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            img_suffix=img_suffix, seg_map_suffix=seg_map_suffix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b978899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:30.574056Z",
     "iopub.status.busy": "2023-05-11T10:19:30.573188Z",
     "iopub.status.idle": "2023-05-11T10:19:30.578516Z",
     "shell.execute_reply": "2023-05-11T10:19:30.577712Z"
    },
    "papermill": {
     "duration": 0.087765,
     "end_time": "2023-05-11T10:19:30.580464",
     "exception": false,
     "start_time": "2023-05-11T10:19:30.492699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/working/mmsegmentation/mmseg/datasets/__init__.py', 'r+') as f:\n",
    "    content = f.read()\n",
    "    f.seek(0, 0)\n",
    "    f.write(\"from .isicdataset import ISICDataset\\n\" + content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d380e644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:30.739427Z",
     "iopub.status.busy": "2023-05-11T10:19:30.739155Z",
     "iopub.status.idle": "2023-05-11T10:19:30.746803Z",
     "shell.execute_reply": "2023-05-11T10:19:30.745506Z"
    },
    "papermill": {
     "duration": 0.089367,
     "end_time": "2023-05-11T10:19:30.748717",
     "exception": false,
     "start_time": "2023-05-11T10:19:30.659350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/mmsegmentation/configs/_base_/datasets/isic_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmsegmentation/configs/_base_/datasets/isic_dataset.py\n",
    "# dataset settings\n",
    "dataset_type = 'ISICDataset'\n",
    "data_root = '/kaggle/input/isic-2018/data'\n",
    "img_scale = (2048,1024)\n",
    "crop_size = (512,512)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='ConvertPixel'),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=img_scale,\n",
    "        ratio_range=(0.5, 2.0),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='GenerateEdge', edge_width=4),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "\n",
    "val_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=img_scale, keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='ConvertPixel'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=img_scale, keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='ConvertPixel'),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]\n",
    "\n",
    "tta_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(\n",
    "        type='TestTimeAug',\n",
    "        transforms=[\n",
    "            [\n",
    "                dict(type='Resize', scale_factor=r, keep_ratio=True)\n",
    "                for r in img_ratios\n",
    "            ],\n",
    "            [\n",
    "                dict(type='RandomFlip', prob=0., direction='horizontal'),\n",
    "                dict(type='RandomFlip', prob=1., direction='horizontal')\n",
    "            ], [dict(type='LoadAnnotations')], [dict(type='PackSegInputs')]\n",
    "        ])\n",
    "]\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
    "    dataset=dict(\n",
    "        type='RepeatDataset',\n",
    "        times=40000,\n",
    "        dataset=dict(\n",
    "            type=dataset_type,\n",
    "            data_root=data_root,\n",
    "            data_prefix=dict(\n",
    "                img_path='images/train',\n",
    "                seg_map_path='annotations/train'),\n",
    "            pipeline=train_pipeline)))\n",
    "\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        data_prefix=dict(\n",
    "            img_path='images/val',\n",
    "            seg_map_path='annotations/val'),\n",
    "        pipeline=val_pipeline))\n",
    "\n",
    "test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        data_prefix=dict(\n",
    "            img_path='images/test',\n",
    "            seg_map_path='annotations/test'),\n",
    "        pipeline=test_pipeline))\n",
    "\n",
    "val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])\n",
    "test_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'], format_only=True, keep_results=True, output_dir='/kaggle/working/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c47e810f",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:30.909050Z",
     "iopub.status.busy": "2023-05-11T10:19:30.908718Z",
     "iopub.status.idle": "2023-05-11T10:19:30.932213Z",
     "shell.execute_reply": "2023-05-11T10:19:30.930801Z"
    },
    "papermill": {
     "duration": 0.107272,
     "end_time": "2023-05-11T10:19:30.934443",
     "exception": false,
     "start_time": "2023-05-11T10:19:30.827171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/mmsegmentation/mmseg/utils/class_names.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmsegmentation/mmseg/utils/class_names.py\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from mmengine.utils import is_str\n",
    "\n",
    "\n",
    "def cityscapes_classes():\n",
    "    \"\"\"Cityscapes class names for external use.\"\"\"\n",
    "    return [\n",
    "        'road', 'sidewalk', 'building', 'wall', 'fence', 'pole',\n",
    "        'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky',\n",
    "        'person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle',\n",
    "        'bicycle'\n",
    "    ]\n",
    "\n",
    "\n",
    "def ade_classes():\n",
    "    \"\"\"ADE20K class names for external use.\"\"\"\n",
    "    return [\n",
    "        'wall', 'building', 'sky', 'floor', 'tree', 'ceiling', 'road', 'bed ',\n",
    "        'windowpane', 'grass', 'cabinet', 'sidewalk', 'person', 'earth',\n",
    "        'door', 'table', 'mountain', 'plant', 'curtain', 'chair', 'car',\n",
    "        'water', 'painting', 'sofa', 'shelf', 'house', 'sea', 'mirror', 'rug',\n",
    "        'field', 'armchair', 'seat', 'fence', 'desk', 'rock', 'wardrobe',\n",
    "        'lamp', 'bathtub', 'railing', 'cushion', 'base', 'box', 'column',\n",
    "        'signboard', 'chest of drawers', 'counter', 'sand', 'sink',\n",
    "        'skyscraper', 'fireplace', 'refrigerator', 'grandstand', 'path',\n",
    "        'stairs', 'runway', 'case', 'pool table', 'pillow', 'screen door',\n",
    "        'stairway', 'river', 'bridge', 'bookcase', 'blind', 'coffee table',\n",
    "        'toilet', 'flower', 'book', 'hill', 'bench', 'countertop', 'stove',\n",
    "        'palm', 'kitchen island', 'computer', 'swivel chair', 'boat', 'bar',\n",
    "        'arcade machine', 'hovel', 'bus', 'towel', 'light', 'truck', 'tower',\n",
    "        'chandelier', 'awning', 'streetlight', 'booth', 'television receiver',\n",
    "        'airplane', 'dirt track', 'apparel', 'pole', 'land', 'bannister',\n",
    "        'escalator', 'ottoman', 'bottle', 'buffet', 'poster', 'stage', 'van',\n",
    "        'ship', 'fountain', 'conveyer belt', 'canopy', 'washer', 'plaything',\n",
    "        'swimming pool', 'stool', 'barrel', 'basket', 'waterfall', 'tent',\n",
    "        'bag', 'minibike', 'cradle', 'oven', 'ball', 'food', 'step', 'tank',\n",
    "        'trade name', 'microwave', 'pot', 'animal', 'bicycle', 'lake',\n",
    "        'dishwasher', 'screen', 'blanket', 'sculpture', 'hood', 'sconce',\n",
    "        'vase', 'traffic light', 'tray', 'ashcan', 'fan', 'pier', 'crt screen',\n",
    "        'plate', 'monitor', 'bulletin board', 'shower', 'radiator', 'glass',\n",
    "        'clock', 'flag'\n",
    "    ]\n",
    "\n",
    "\n",
    "def voc_classes():\n",
    "    \"\"\"Pascal VOC class names for external use.\"\"\"\n",
    "    return [\n",
    "        'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "        'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "        'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',\n",
    "        'tvmonitor'\n",
    "    ]\n",
    "\n",
    "\n",
    "def cocostuff_classes():\n",
    "    \"\"\"CocoStuff class names for external use.\"\"\"\n",
    "    return [\n",
    "        'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',\n",
    "        'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'banner',\n",
    "        'blanket', 'branch', 'bridge', 'building-other', 'bush', 'cabinet',\n",
    "        'cage', 'cardboard', 'carpet', 'ceiling-other', 'ceiling-tile',\n",
    "        'cloth', 'clothes', 'clouds', 'counter', 'cupboard', 'curtain',\n",
    "        'desk-stuff', 'dirt', 'door-stuff', 'fence', 'floor-marble',\n",
    "        'floor-other', 'floor-stone', 'floor-tile', 'floor-wood', 'flower',\n",
    "        'fog', 'food-other', 'fruit', 'furniture-other', 'grass', 'gravel',\n",
    "        'ground-other', 'hill', 'house', 'leaves', 'light', 'mat', 'metal',\n",
    "        'mirror-stuff', 'moss', 'mountain', 'mud', 'napkin', 'net', 'paper',\n",
    "        'pavement', 'pillow', 'plant-other', 'plastic', 'platform',\n",
    "        'playingfield', 'railing', 'railroad', 'river', 'road', 'rock', 'roof',\n",
    "        'rug', 'salad', 'sand', 'sea', 'shelf', 'sky-other', 'skyscraper',\n",
    "        'snow', 'solid-other', 'stairs', 'stone', 'straw', 'structural-other',\n",
    "        'table', 'tent', 'textile-other', 'towel', 'tree', 'vegetable',\n",
    "        'wall-brick', 'wall-concrete', 'wall-other', 'wall-panel',\n",
    "        'wall-stone', 'wall-tile', 'wall-wood', 'water-other', 'waterdrops',\n",
    "        'window-blind', 'window-other', 'wood'\n",
    "    ]\n",
    "\n",
    "\n",
    "def loveda_classes():\n",
    "    \"\"\"LoveDA class names for external use.\"\"\"\n",
    "    return [\n",
    "        'background', 'building', 'road', 'water', 'barren', 'forest',\n",
    "        'agricultural'\n",
    "    ]\n",
    "\n",
    "\n",
    "def potsdam_classes():\n",
    "    \"\"\"Potsdam class names for external use.\"\"\"\n",
    "    return [\n",
    "        'impervious_surface', 'building', 'low_vegetation', 'tree', 'car',\n",
    "        'clutter'\n",
    "    ]\n",
    "\n",
    "\n",
    "def vaihingen_classes():\n",
    "    \"\"\"Vaihingen class names for external use.\"\"\"\n",
    "    return [\n",
    "        'impervious_surface', 'building', 'low_vegetation', 'tree', 'car',\n",
    "        'clutter'\n",
    "    ]\n",
    "\n",
    "\n",
    "def isaid_classes():\n",
    "    \"\"\"iSAID class names for external use.\"\"\"\n",
    "    return [\n",
    "        'background', 'ship', 'store_tank', 'baseball_diamond', 'tennis_court',\n",
    "        'basketball_court', 'Ground_Track_Field', 'Bridge', 'Large_Vehicle',\n",
    "        'Small_Vehicle', 'Helicopter', 'Swimming_pool', 'Roundabout',\n",
    "        'Soccer_ball_field', 'plane', 'Harbor'\n",
    "    ]\n",
    "\n",
    "\n",
    "def stare_classes():\n",
    "    \"\"\"stare class names for external use.\"\"\"\n",
    "    return ['background', 'vessel']\n",
    "\n",
    "\n",
    "def mapillary_v1_classes():\n",
    "    \"\"\"mapillary_v1 class names for external use.\"\"\"\n",
    "    return [\n",
    "        'Bird', 'Ground Animal', 'Curb', 'Fence', 'Guard Rail', 'Barrier',\n",
    "        'Wall', 'Bike Lane', 'Crosswalk - Plain', 'Curb Cut', 'Parking',\n",
    "        'Pedestrian Area', 'Rail Track', 'Road', 'Service Lane', 'Sidewalk',\n",
    "        'Bridge', 'Building', 'Tunnel', 'Person', 'Bicyclist', 'Motorcyclist',\n",
    "        'Other Rider', 'Lane Marking - Crosswalk', 'Lane Marking - General',\n",
    "        'Mountain', 'Sand', 'Sky', 'Snow', 'Terrain', 'Vegetation', 'Water',\n",
    "        'Banner', 'Bench', 'Bike Rack', 'Billboard', 'Catch Basin',\n",
    "        'CCTV Camera', 'Fire Hydrant', 'Junction Box', 'Mailbox', 'Manhole',\n",
    "        'Phone Booth', 'Pothole', 'Street Light', 'Pole', 'Traffic Sign Frame',\n",
    "        'Utility Pole', 'Traffic Light', 'Traffic Sign (Back)',\n",
    "        'Traffic Sign (Front)', 'Trash Can', 'Bicycle', 'Boat', 'Bus', 'Car',\n",
    "        'Caravan', 'Motorcycle', 'On Rails', 'Other Vehicle', 'Trailer',\n",
    "        'Truck', 'Wheeled Slow', 'Car Mount', 'Ego Vehicle', 'Unlabeled'\n",
    "    ]\n",
    "\n",
    "\n",
    "def mapillary_v1_palette():\n",
    "    \"\"\"mapillary_v1_ palette for external use.\"\"\"\n",
    "    return [[165, 42, 42], [0, 192, 0], [196, 196, 196], [190, 153, 153],\n",
    "            [180, 165, 180], [90, 120, 150], [102, 102, 156], [128, 64, 255],\n",
    "            [140, 140, 200], [170, 170, 170], [250, 170, 160], [96, 96, 96],\n",
    "            [230, 150, 140], [128, 64, 128], [110, 110, 110], [244, 35, 232],\n",
    "            [150, 100, 100], [70, 70, 70], [150, 120, 90], [220, 20, 60],\n",
    "            [255, 0, 0], [255, 0, 100], [255, 0, 200], [200, 128, 128],\n",
    "            [255, 255, 255], [64, 170, 64], [230, 160, 50], [70, 130, 180],\n",
    "            [190, 255, 255], [152, 251, 152], [107, 142, 35], [0, 170, 30],\n",
    "            [255, 255, 128], [250, 0, 30], [100, 140, 180], [220, 220, 220],\n",
    "            [220, 128, 128], [222, 40, 40], [100, 170, 30], [40, 40, 40],\n",
    "            [33, 33, 33], [100, 128, 160], [142, 0, 0], [70, 100, 150],\n",
    "            [210, 170, 100], [153, 153, 153], [128, 128, 128], [0, 0, 80],\n",
    "            [250, 170, 30], [192, 192, 192], [220, 220, 0], [140, 140, 20],\n",
    "            [119, 11, 32], [150, 0, 255], [0, 60, 100], [0, 0, 142],\n",
    "            [0, 0, 90], [0, 0, 230], [0, 80, 100], [128, 64, 64], [0, 0, 110],\n",
    "            [0, 0, 70], [0, 0, 192], [32, 32, 32], [120, 10, 10], [0, 0, 0]]\n",
    "\n",
    "\n",
    "def mapillary_v2_classes():\n",
    "    \"\"\"mapillary_v2 class names for external use.\"\"\"\n",
    "    return [\n",
    "        'Bird', 'Ground Animal', 'Ambiguous Barrier', 'Concrete Block', 'Curb',\n",
    "        'Fence', 'Guard Rail', 'Barrier', 'Road Median', 'Road Side',\n",
    "        'Lane Separator', 'Temporary Barrier', 'Wall', 'Bike Lane',\n",
    "        'Crosswalk - Plain', 'Curb Cut', 'Driveway', 'Parking',\n",
    "        'Parking Aisle', 'Pedestrian Area', 'Rail Track', 'Road',\n",
    "        'Road Shoulder', 'Service Lane', 'Sidewalk', 'Traffic Island',\n",
    "        'Bridge', 'Building', 'Garage', 'Tunnel', 'Person', 'Person Group',\n",
    "        'Bicyclist', 'Motorcyclist', 'Other Rider',\n",
    "        'Lane Marking - Dashed Line', 'Lane Marking - Straight Line',\n",
    "        'Lane Marking - Zigzag Line', 'Lane Marking - Ambiguous',\n",
    "        'Lane Marking - Arrow (Left)', 'Lane Marking - Arrow (Other)',\n",
    "        'Lane Marking - Arrow (Right)',\n",
    "        'Lane Marking - Arrow (Split Left or Straight)',\n",
    "        'Lane Marking - Arrow (Split Right or Straight)',\n",
    "        'Lane Marking - Arrow (Straight)', 'Lane Marking - Crosswalk',\n",
    "        'Lane Marking - Give Way (Row)', 'Lane Marking - Give Way (Single)',\n",
    "        'Lane Marking - Hatched (Chevron)',\n",
    "        'Lane Marking - Hatched (Diagonal)', 'Lane Marking - Other',\n",
    "        'Lane Marking - Stop Line', 'Lane Marking - Symbol (Bicycle)',\n",
    "        'Lane Marking - Symbol (Other)', 'Lane Marking - Text',\n",
    "        'Lane Marking (only) - Dashed Line', 'Lane Marking (only) - Crosswalk',\n",
    "        'Lane Marking (only) - Other', 'Lane Marking (only) - Test',\n",
    "        'Mountain', 'Sand', 'Sky', 'Snow', 'Terrain', 'Vegetation', 'Water',\n",
    "        'Banner', 'Bench', 'Bike Rack', 'Catch Basin', 'CCTV Camera',\n",
    "        'Fire Hydrant', 'Junction Box', 'Mailbox', 'Manhole', 'Parking Meter',\n",
    "        'Phone Booth', 'Pothole', 'Signage - Advertisement',\n",
    "        'Signage - Ambiguous', 'Signage - Back', 'Signage - Information',\n",
    "        'Signage - Other', 'Signage - Store', 'Street Light', 'Pole',\n",
    "        'Pole Group', 'Traffic Sign Frame', 'Utility Pole', 'Traffic Cone',\n",
    "        'Traffic Light - General (Single)', 'Traffic Light - Pedestrians',\n",
    "        'Traffic Light - General (Upright)',\n",
    "        'Traffic Light - General (Horizontal)', 'Traffic Light - Cyclists',\n",
    "        'Traffic Light - Other', 'Traffic Sign - Ambiguous',\n",
    "        'Traffic Sign (Back)', 'Traffic Sign - Direction (Back)',\n",
    "        'Traffic Sign - Direction (Front)', 'Traffic Sign (Front)',\n",
    "        'Traffic Sign - Parking', 'Traffic Sign - Temporary (Back)',\n",
    "        'Traffic Sign - Temporary (Front)', 'Trash Can', 'Bicycle', 'Boat',\n",
    "        'Bus', 'Car', 'Caravan', 'Motorcycle', 'On Rails', 'Other Vehicle',\n",
    "        'Trailer', 'Truck', 'Vehicle Group', 'Wheeled Slow', 'Water Valve',\n",
    "        'Car Mount', 'Dynamic', 'Ego Vehicle', 'Ground', 'Static', 'Unlabeled'\n",
    "    ]\n",
    "\n",
    "\n",
    "def mapillary_v2_palette():\n",
    "    \"\"\"mapillary_v2_ palette for external use.\"\"\"\n",
    "    return [[165, 42, 42], [0, 192, 0], [250, 170, 31], [250, 170, 32],\n",
    "            [196, 196, 196], [190, 153, 153], [180, 165, 180], [90, 120, 150],\n",
    "            [250, 170, 33], [250, 170, 34], [128, 128, 128], [250, 170, 35],\n",
    "            [102, 102, 156], [128, 64, 255], [140, 140, 200], [170, 170, 170],\n",
    "            [250, 170, 36], [250, 170, 160], [250, 170, 37], [96, 96, 96],\n",
    "            [230, 150, 140], [128, 64, 128], [110, 110, 110], [110, 110, 110],\n",
    "            [244, 35, 232], [128, 196, 128], [150, 100, 100], [70, 70, 70],\n",
    "            [150, 150, 150], [150, 120, 90], [220, 20, 60], [220, 20, 60],\n",
    "            [255, 0, 0], [255, 0, 100], [255, 0, 200], [255, 255, 255],\n",
    "            [255, 255, 255], [250, 170, 29], [250, 170, 28], [250, 170, 26],\n",
    "            [250, 170, 25], [250, 170, 24], [250, 170, 22], [250, 170, 21],\n",
    "            [250, 170, 20], [255, 255, 255], [250, 170, 19], [250, 170, 18],\n",
    "            [250, 170, 12], [250, 170, 11], [255, 255, 255], [255, 255, 255],\n",
    "            [250, 170, 16], [250, 170, 15], [250, 170, 15], [255, 255, 255],\n",
    "            [255, 255, 255], [255, 255, 255], [255, 255, 255], [64, 170, 64],\n",
    "            [230, 160, 50], [70, 130, 180], [190, 255, 255], [152, 251, 152],\n",
    "            [107, 142, 35], [0, 170, 30], [255, 255, 128], [250, 0, 30],\n",
    "            [100, 140, 180], [220, 128, 128], [222, 40, 40], [100, 170, 30],\n",
    "            [40, 40, 40], [33, 33, 33], [100, 128, 160], [20, 20, 255],\n",
    "            [142, 0, 0], [70, 100, 150], [250, 171, 30], [250, 172, 30],\n",
    "            [250, 173, 30], [250, 174, 30], [250, 175, 30], [250, 176, 30],\n",
    "            [210, 170, 100], [153, 153, 153], [153, 153, 153], [128, 128, 128],\n",
    "            [0, 0, 80], [210, 60, 60], [250, 170, 30], [250, 170, 30],\n",
    "            [250, 170, 30], [250, 170, 30], [250, 170, 30], [250, 170, 30],\n",
    "            [192, 192, 192], [192, 192, 192], [192, 192, 192], [220, 220, 0],\n",
    "            [220, 220, 0], [0, 0, 196], [192, 192, 192], [220, 220, 0],\n",
    "            [140, 140, 20], [119, 11, 32], [150, 0, 255], [0, 60, 100],\n",
    "            [0, 0, 142], [0, 0, 90], [0, 0, 230], [0, 80, 100], [128, 64, 64],\n",
    "            [0, 0, 110], [0, 0, 70], [0, 0, 142], [0, 0, 192], [170, 170, 170],\n",
    "            [32, 32, 32], [111, 74, 0], [120, 10, 10], [81, 0, 81],\n",
    "            [111, 111, 0], [0, 0, 0]]\n",
    "\n",
    "\n",
    "def cityscapes_palette():\n",
    "    \"\"\"Cityscapes palette for external use.\"\"\"\n",
    "    return [[128, 64, 128], [244, 35, 232], [70, 70, 70], [102, 102, 156],\n",
    "            [190, 153, 153], [153, 153, 153], [250, 170, 30], [220, 220, 0],\n",
    "            [107, 142, 35], [152, 251, 152], [70, 130, 180], [220, 20, 60],\n",
    "            [255, 0, 0], [0, 0, 142], [0, 0, 70], [0, 60, 100], [0, 80, 100],\n",
    "            [0, 0, 230], [119, 11, 32]]\n",
    "\n",
    "\n",
    "def ade_palette():\n",
    "    \"\"\"ADE20K palette for external use.\"\"\"\n",
    "    return [[120, 120, 120], [180, 120, 120], [6, 230, 230], [80, 50, 50],\n",
    "            [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255],\n",
    "            [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7],\n",
    "            [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82],\n",
    "            [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3],\n",
    "            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],\n",
    "            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],\n",
    "            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],\n",
    "            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],\n",
    "            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],\n",
    "            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],\n",
    "            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],\n",
    "            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],\n",
    "            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],\n",
    "            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],\n",
    "            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],\n",
    "            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],\n",
    "            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],\n",
    "            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],\n",
    "            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],\n",
    "            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],\n",
    "            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],\n",
    "            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],\n",
    "            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],\n",
    "            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],\n",
    "            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],\n",
    "            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],\n",
    "            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],\n",
    "            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],\n",
    "            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],\n",
    "            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],\n",
    "            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],\n",
    "            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],\n",
    "            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],\n",
    "            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],\n",
    "            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],\n",
    "            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],\n",
    "            [102, 255, 0], [92, 0, 255]]\n",
    "\n",
    "\n",
    "def voc_palette():\n",
    "    \"\"\"Pascal VOC palette for external use.\"\"\"\n",
    "    return [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128],\n",
    "            [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0],\n",
    "            [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128],\n",
    "            [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0],\n",
    "            [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]]\n",
    "\n",
    "\n",
    "def cocostuff_palette():\n",
    "    \"\"\"CocoStuff palette for external use.\"\"\"\n",
    "    return [[0, 192, 64], [0, 192, 64], [0, 64, 96], [128, 192, 192],\n",
    "            [0, 64, 64], [0, 192, 224], [0, 192, 192], [128, 192, 64],\n",
    "            [0, 192, 96], [128, 192, 64], [128, 32, 192], [0, 0, 224],\n",
    "            [0, 0, 64], [0, 160, 192], [128, 0, 96], [128, 0, 192],\n",
    "            [0, 32, 192], [128, 128, 224], [0, 0, 192], [128, 160, 192],\n",
    "            [128, 128, 0], [128, 0, 32], [128, 32, 0], [128, 0, 128],\n",
    "            [64, 128, 32], [0, 160, 0], [0, 0, 0], [192, 128, 160], [0, 32, 0],\n",
    "            [0, 128, 128], [64, 128, 160], [128, 160, 0], [0, 128, 0],\n",
    "            [192, 128, 32], [128, 96, 128], [0, 0, 128], [64, 0, 32],\n",
    "            [0, 224, 128], [128, 0, 0], [192, 0, 160], [0, 96, 128],\n",
    "            [128, 128, 128], [64, 0, 160], [128, 224, 128], [128, 128, 64],\n",
    "            [192, 0, 32], [128, 96, 0], [128, 0, 192], [0, 128, 32],\n",
    "            [64, 224, 0], [0, 0, 64], [128, 128, 160], [64, 96, 0],\n",
    "            [0, 128, 192], [0, 128, 160], [192, 224, 0], [0, 128, 64],\n",
    "            [128, 128, 32], [192, 32, 128], [0, 64, 192], [0, 0, 32],\n",
    "            [64, 160, 128], [128, 64, 64], [128, 0, 160], [64, 32, 128],\n",
    "            [128, 192, 192], [0, 0, 160], [192, 160, 128], [128, 192, 0],\n",
    "            [128, 0, 96], [192, 32, 0], [128, 64, 128], [64, 128, 96],\n",
    "            [64, 160, 0], [0, 64, 0], [192, 128, 224], [64, 32, 0],\n",
    "            [0, 192, 128], [64, 128, 224], [192, 160, 0], [0, 192, 0],\n",
    "            [192, 128, 96], [192, 96, 128], [0, 64, 128], [64, 0, 96],\n",
    "            [64, 224, 128], [128, 64, 0], [192, 0, 224], [64, 96, 128],\n",
    "            [128, 192, 128], [64, 0, 224], [192, 224, 128], [128, 192, 64],\n",
    "            [192, 0, 96], [192, 96, 0], [128, 64, 192], [0, 128, 96],\n",
    "            [0, 224, 0], [64, 64, 64], [128, 128, 224], [0, 96, 0],\n",
    "            [64, 192, 192], [0, 128, 224], [128, 224, 0], [64, 192, 64],\n",
    "            [128, 128, 96], [128, 32, 128], [64, 0, 192], [0, 64, 96],\n",
    "            [0, 160, 128], [192, 0, 64], [128, 64, 224], [0, 32, 128],\n",
    "            [192, 128, 192], [0, 64, 224], [128, 160, 128], [192, 128, 0],\n",
    "            [128, 64, 32], [128, 32, 64], [192, 0, 128], [64, 192, 32],\n",
    "            [0, 160, 64], [64, 0, 0], [192, 192, 160], [0, 32, 64],\n",
    "            [64, 128, 128], [64, 192, 160], [128, 160, 64], [64, 128, 0],\n",
    "            [192, 192, 32], [128, 96, 192], [64, 0, 128], [64, 64, 32],\n",
    "            [0, 224, 192], [192, 0, 0], [192, 64, 160], [0, 96, 192],\n",
    "            [192, 128, 128], [64, 64, 160], [128, 224, 192], [192, 128, 64],\n",
    "            [192, 64, 32], [128, 96, 64], [192, 0, 192], [0, 192, 32],\n",
    "            [64, 224, 64], [64, 0, 64], [128, 192, 160], [64, 96, 64],\n",
    "            [64, 128, 192], [0, 192, 160], [192, 224, 64], [64, 128, 64],\n",
    "            [128, 192, 32], [192, 32, 192], [64, 64, 192], [0, 64, 32],\n",
    "            [64, 160, 192], [192, 64, 64], [128, 64, 160], [64, 32, 192],\n",
    "            [192, 192, 192], [0, 64, 160], [192, 160, 192], [192, 192, 0],\n",
    "            [128, 64, 96], [192, 32, 64], [192, 64, 128], [64, 192, 96],\n",
    "            [64, 160, 64], [64, 64, 0]]\n",
    "\n",
    "\n",
    "def loveda_palette():\n",
    "    \"\"\"LoveDA palette for external use.\"\"\"\n",
    "    return [[255, 255, 255], [255, 0, 0], [255, 255, 0], [0, 0, 255],\n",
    "            [159, 129, 183], [0, 255, 0], [255, 195, 128]]\n",
    "\n",
    "\n",
    "def potsdam_palette():\n",
    "    \"\"\"Potsdam palette for external use.\"\"\"\n",
    "    return [[255, 255, 255], [0, 0, 255], [0, 255, 255], [0, 255, 0],\n",
    "            [255, 255, 0], [255, 0, 0]]\n",
    "\n",
    "\n",
    "def vaihingen_palette():\n",
    "    \"\"\"Vaihingen palette for external use.\"\"\"\n",
    "    return [[255, 255, 255], [0, 0, 255], [0, 255, 255], [0, 255, 0],\n",
    "            [255, 255, 0], [255, 0, 0]]\n",
    "\n",
    "\n",
    "def isaid_palette():\n",
    "    \"\"\"iSAID palette for external use.\"\"\"\n",
    "    return [[0, 0, 0], [0, 0, 63], [0, 63, 63], [0, 63, 0], [0, 63, 127],\n",
    "            [0, 63, 191], [0, 63, 255], [0, 127, 63], [0, 127,\n",
    "                                                       127], [0, 0, 127],\n",
    "            [0, 0, 191], [0, 0, 255], [0, 191, 127], [0, 127, 191],\n",
    "            [0, 127, 255], [0, 100, 155]]\n",
    "\n",
    "\n",
    "def stare_palette():\n",
    "    \"\"\"STARE palette for external use.\"\"\"\n",
    "    return [[120, 120, 120], [6, 230, 230]]\n",
    "\n",
    "\n",
    "def synapse_palette():\n",
    "    \"\"\"Synapse palette for external use.\"\"\"\n",
    "    return [[0, 0, 0], [0, 0, 255], [0, 255, 0], [255, 0, 0], [0, 255, 255],\n",
    "            [255, 0, 255], [255, 255, 0], [60, 255, 255], [240, 240, 240]]\n",
    "\n",
    "\n",
    "def synapse_classes():\n",
    "    \"\"\"Synapse class names for external use.\"\"\"\n",
    "    return [\n",
    "        'background', 'aorta', 'gallbladder', 'left_kidney', 'right_kidney',\n",
    "        'liver', 'pancreas', 'spleen', 'stomach'\n",
    "    ]\n",
    "\n",
    "\n",
    "def lip_classes():\n",
    "    \"\"\"LIP class names for external use.\"\"\"\n",
    "    return [\n",
    "        'background', 'hat', 'hair', 'glove', 'sunglasses', 'upperclothes',\n",
    "        'dress', 'coat', 'socks', 'pants', 'jumpsuits', 'scarf', 'skirt',\n",
    "        'face', 'leftArm', 'rightArm', 'leftLeg', 'rightLeg', 'leftShoe',\n",
    "        'rightShoe'\n",
    "    ]\n",
    "\n",
    "\n",
    "def lip_palette():\n",
    "    \"\"\"LIP palette for external use.\"\"\"\n",
    "    return [\n",
    "        'Background', 'Hat', 'Hair', 'Glove', 'Sunglasses', 'UpperClothes',\n",
    "        'Dress', 'Coat', 'Socks', 'Pants', 'Jumpsuits', 'Scarf', 'Skirt',\n",
    "        'Face', 'Left-arm', 'Right-arm', 'Left-leg', 'Right-leg', 'Left-shoe',\n",
    "        'Right-shoe'\n",
    "    ]\n",
    "\n",
    "def isic_class():\n",
    "    return ['background', 'mask']\n",
    "\n",
    "def isic_palette():\n",
    "    return [[0, 0, 0], [255, 255, 255]]\n",
    "\n",
    "dataset_aliases = {\n",
    "    'cityscapes': ['cityscapes'],\n",
    "    'ade': ['ade', 'ade20k'],\n",
    "    'voc': ['voc', 'pascal_voc', 'voc12', 'voc12aug'],\n",
    "    'loveda': ['loveda'],\n",
    "    'potsdam': ['potsdam'],\n",
    "    'vaihingen': ['vaihingen'],\n",
    "    'cocostuff': [\n",
    "        'cocostuff', 'cocostuff10k', 'cocostuff164k', 'coco-stuff',\n",
    "        'coco-stuff10k', 'coco-stuff164k', 'coco_stuff', 'coco_stuff10k',\n",
    "        'coco_stuff164k'\n",
    "    ],\n",
    "    'isaid': ['isaid', 'iSAID'],\n",
    "    'stare': ['stare', 'STARE'],\n",
    "    'lip': ['LIP', 'lip'],\n",
    "    'mapillary_v1': ['mapillary_v1'],\n",
    "    'mapillary_v2': ['mapillary_v2'],\n",
    "    'isic':['isic','isic_2018','ISIC'],\n",
    "}\n",
    "\n",
    "\n",
    "def get_classes(dataset):\n",
    "    \"\"\"Get class names of a dataset.\"\"\"\n",
    "    alias2name = {}\n",
    "    for name, aliases in dataset_aliases.items():\n",
    "        for alias in aliases:\n",
    "            alias2name[alias] = name\n",
    "\n",
    "    if is_str(dataset):\n",
    "        if dataset in alias2name:\n",
    "            labels = eval(alias2name[dataset] + '_classes()')\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized dataset: {dataset}')\n",
    "    else:\n",
    "        raise TypeError(f'dataset must a str, but got {type(dataset)}')\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_palette(dataset):\n",
    "    \"\"\"Get class palette (RGB) of a dataset.\"\"\"\n",
    "    alias2name = {}\n",
    "    for name, aliases in dataset_aliases.items():\n",
    "        for alias in aliases:\n",
    "            alias2name[alias] = name\n",
    "\n",
    "    if is_str(dataset):\n",
    "        if dataset in alias2name:\n",
    "            labels = eval(alias2name[dataset] + '_palette()')\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized dataset: {dataset}')\n",
    "    else:\n",
    "        raise TypeError(f'dataset must a str, but got {type(dataset)}')\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "863271fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:31.095205Z",
     "iopub.status.busy": "2023-05-11T10:19:31.094931Z",
     "iopub.status.idle": "2023-05-11T10:19:31.112182Z",
     "shell.execute_reply": "2023-05-11T10:19:31.111163Z"
    },
    "papermill": {
     "duration": 0.099586,
     "end_time": "2023-05-11T10:19:31.114176",
     "exception": false,
     "start_time": "2023-05-11T10:19:31.014590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/mmsegmentation/mmseg/models/backbones/pidnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmsegmentation/mmseg/models/backbones/pidnet.py\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmengine.model import BaseModule\n",
    "from mmengine.runner import CheckpointLoader\n",
    "from torch import Tensor\n",
    "\n",
    "from mmseg.registry import MODELS\n",
    "from mmseg.utils import OptConfigType\n",
    "from ..utils import DAPPM, PAPPM, BasicBlock, Bottleneck\n",
    "\n",
    "\n",
    "class PagFM(BaseModule):\n",
    "    \"\"\"Pixel-attention-guided fusion module.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): The number of input channels.\n",
    "        channels (int): The number of channels.\n",
    "        after_relu (bool): Whether to use ReLU before attention.\n",
    "            Default: False.\n",
    "        with_channel (bool): Whether to use channel attention.\n",
    "            Default: False.\n",
    "        upsample_mode (str): The mode of upsample. Default: 'bilinear'.\n",
    "        norm_cfg (dict): Config dict for normalization layer.\n",
    "            Default: dict(type='BN').\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: dict(typ='ReLU', inplace=True).\n",
    "        init_cfg (dict): Config dict for initialization. Default: None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 channels: int,\n",
    "                 after_relu: bool = False,\n",
    "                 with_channel: bool = False,\n",
    "                 upsample_mode: str = 'bilinear',\n",
    "                 norm_cfg: OptConfigType = dict(type='BN'),\n",
    "                 act_cfg: OptConfigType = dict(typ='ReLU', inplace=True),\n",
    "                 init_cfg: OptConfigType = None):\n",
    "        super().__init__(init_cfg)\n",
    "        self.after_relu = after_relu\n",
    "        self.with_channel = with_channel\n",
    "        self.upsample_mode = upsample_mode\n",
    "        self.f_i = ConvModule(\n",
    "            in_channels, channels, 1, norm_cfg=norm_cfg, act_cfg=None)\n",
    "        self.f_p = ConvModule(\n",
    "            in_channels, channels, 1, norm_cfg=norm_cfg, act_cfg=None)\n",
    "        if with_channel:\n",
    "            self.up = ConvModule(\n",
    "                channels, in_channels, 1, norm_cfg=norm_cfg, act_cfg=None)\n",
    "        if after_relu:\n",
    "            self.relu = MODELS.build(act_cfg)\n",
    "\n",
    "    def forward(self, x_p: Tensor, x_i: Tensor) -> Tensor:\n",
    "        \"\"\"Forward function.\n",
    "\n",
    "        Args:\n",
    "            x_p (Tensor): The featrue map from P branch.\n",
    "            x_i (Tensor): The featrue map from I branch.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The feature map with pixel-attention-guided fusion.\n",
    "        \"\"\"\n",
    "        if self.after_relu:\n",
    "            x_p = self.relu(x_p)\n",
    "            x_i = self.relu(x_i)\n",
    "\n",
    "        f_i = self.f_i(x_i)\n",
    "        f_i = F.interpolate(\n",
    "            f_i,\n",
    "            size=x_p.shape[2:],\n",
    "            mode=self.upsample_mode,\n",
    "            align_corners=False)\n",
    "\n",
    "        f_p = self.f_p(x_p)\n",
    "\n",
    "        if self.with_channel:\n",
    "            sigma = torch.sigmoid(self.up(f_p * f_i))\n",
    "        else:\n",
    "            sigma = torch.sigmoid(torch.sum(f_p * f_i, dim=1).unsqueeze(1))\n",
    "\n",
    "        x_i = F.interpolate(\n",
    "            x_i,\n",
    "            size=x_p.shape[2:],\n",
    "            mode=self.upsample_mode,\n",
    "            align_corners=False)\n",
    "\n",
    "        out = sigma * x_i + (1 - sigma) * x_p\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bag(BaseModule):\n",
    "    \"\"\"Boundary-attention-guided fusion module.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): The number of input channels.\n",
    "        out_channels (int): The number of output channels.\n",
    "        kernel_size (int): The kernel size of the convolution. Default: 3.\n",
    "        padding (int): The padding of the convolution. Default: 1.\n",
    "        norm_cfg (dict): Config dict for normalization layer.\n",
    "            Default: dict(type='BN').\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: dict(type='ReLU', inplace=True).\n",
    "        conv_cfg (dict): Config dict for convolution layer.\n",
    "            Default: dict(order=('norm', 'act', 'conv')).\n",
    "        init_cfg (dict): Config dict for initialization. Default: None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 3,\n",
    "                 padding: int = 1,\n",
    "                 norm_cfg: OptConfigType = dict(type='BN'),\n",
    "                 act_cfg: OptConfigType = dict(type='ReLU', inplace=True),\n",
    "                 conv_cfg: OptConfigType = dict(order=('norm', 'act', 'conv')),\n",
    "                 init_cfg: OptConfigType = None):\n",
    "        super().__init__(init_cfg)\n",
    "\n",
    "        self.conv = ConvModule(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            padding=padding,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            **conv_cfg)\n",
    "\n",
    "    def forward(self, x_p: Tensor, x_i: Tensor, x_d: Tensor) -> Tensor:\n",
    "        \"\"\"Forward function.\n",
    "\n",
    "        Args:\n",
    "            x_p (Tensor): The featrue map from P branch.\n",
    "            x_i (Tensor): The featrue map from I branch.\n",
    "            x_d (Tensor): The featrue map from D branch.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The feature map with boundary-attention-guided fusion.\n",
    "        \"\"\"\n",
    "        sigma = torch.sigmoid(x_d)\n",
    "        return self.conv(sigma * x_p + (1 - sigma) * x_i)\n",
    "\n",
    "\n",
    "class LightBag(BaseModule):\n",
    "    \"\"\"Light Boundary-attention-guided fusion module.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): The number of input channels.\n",
    "        out_channels (int): The number of output channels.\n",
    "        norm_cfg (dict): Config dict for normalization layer.\n",
    "            Default: dict(type='BN').\n",
    "        act_cfg (dict): Config dict for activation layer. Default: None.\n",
    "        init_cfg (dict): Config dict for initialization. Default: None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 norm_cfg: OptConfigType = dict(type='BN'),\n",
    "                 act_cfg: OptConfigType = None,\n",
    "                 init_cfg: OptConfigType = None):\n",
    "        super().__init__(init_cfg)\n",
    "        self.f_p = ConvModule(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg)\n",
    "        self.f_i = ConvModule(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg)\n",
    "\n",
    "    def forward(self, x_p: Tensor, x_i: Tensor, x_d: Tensor) -> Tensor:\n",
    "        \"\"\"Forward function.\n",
    "        Args:\n",
    "            x_p (Tensor): The featrue map from P branch.\n",
    "            x_i (Tensor): The featrue map from I branch.\n",
    "            x_d (Tensor): The featrue map from D branch.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The feature map with light boundary-attention-guided\n",
    "                fusion.\n",
    "        \"\"\"\n",
    "        sigma = torch.sigmoid(x_d)\n",
    "\n",
    "        f_p = self.f_p((1 - sigma) * x_i + x_p)\n",
    "        f_i = self.f_i(x_i + sigma * x_p)\n",
    "\n",
    "        return f_p + f_i\n",
    "\n",
    "\n",
    "@MODELS.register_module()\n",
    "class PIDNet(BaseModule):\n",
    "    \"\"\"PIDNet backbone.\n",
    "\n",
    "    This backbone is the implementation of `PIDNet: A Real-time Semantic\n",
    "    Segmentation Network Inspired from PID Controller\n",
    "    <https://arxiv.org/abs/2206.02066>`_.\n",
    "    Modified from https://github.com/XuJiacong/PIDNet.\n",
    "\n",
    "    Licensed under the MIT License.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): The number of input channels. Default: 3.\n",
    "        channels (int): The number of channels in the stem layer. Default: 64.\n",
    "        ppm_channels (int): The number of channels in the PPM layer.\n",
    "            Default: 96.\n",
    "        num_stem_blocks (int): The number of blocks in the stem layer.\n",
    "            Default: 2.\n",
    "        num_branch_blocks (int): The number of blocks in the branch layer.\n",
    "            Default: 3.\n",
    "        align_corners (bool): The align_corners argument of F.interpolate.\n",
    "            Default: False.\n",
    "        norm_cfg (dict): Config dict for normalization layer.\n",
    "            Default: dict(type='BN').\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: dict(type='ReLU', inplace=True).\n",
    "        init_cfg (dict): Config dict for initialization. Default: None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 channels: int = 64,\n",
    "                 ppm_channels: int = 96,\n",
    "                 num_stem_blocks: int = 2,\n",
    "                 num_branch_blocks: int = 3,\n",
    "                 align_corners: bool = False,\n",
    "                 norm_cfg: OptConfigType = dict(type='BN'),\n",
    "                 act_cfg: OptConfigType = dict(type='ReLU', inplace=True),\n",
    "                 init_cfg: OptConfigType = None,\n",
    "                 **kwargs):\n",
    "        super().__init__(init_cfg)\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.align_corners = align_corners\n",
    "\n",
    "        # stem layer\n",
    "        self.stem = self._make_stem_layer(in_channels, channels,\n",
    "                                          num_stem_blocks)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # I Branch\n",
    "        self.i_branch_layers = nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.i_branch_layers.append(\n",
    "                self._make_layer(\n",
    "                    block=BasicBlock if i < 2 else Bottleneck,\n",
    "                    in_channels=channels * 2**(i + 1),\n",
    "                    channels=channels * 8 if i > 0 else channels * 4,\n",
    "                    num_blocks=num_branch_blocks if i < 2 else 2,\n",
    "                    stride=2))\n",
    "\n",
    "        # P Branch\n",
    "        self.p_branch_layers = nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.p_branch_layers.append(\n",
    "                self._make_layer(\n",
    "                    block=BasicBlock if i < 2 else Bottleneck,\n",
    "                    in_channels=channels * 2,\n",
    "                    channels=channels * 2,\n",
    "                    num_blocks=num_stem_blocks if i < 2 else 1))\n",
    "        self.compression_1 = ConvModule(\n",
    "            channels * 4,\n",
    "            channels * 2,\n",
    "            kernel_size=1,\n",
    "            bias=False,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=None)\n",
    "        self.compression_2 = ConvModule(\n",
    "            channels * 8,\n",
    "            channels * 2,\n",
    "            kernel_size=1,\n",
    "            bias=False,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=None)\n",
    "        self.pag_1 = PagFM(channels * 2, channels)\n",
    "        self.pag_2 = PagFM(channels * 2, channels)\n",
    "\n",
    "        # D Branch\n",
    "        if num_stem_blocks == 2:\n",
    "            self.d_branch_layers = nn.ModuleList([\n",
    "                self._make_single_layer(BasicBlock, channels * 2, channels),\n",
    "                self._make_layer(Bottleneck, channels, channels, 1)\n",
    "            ])\n",
    "            channel_expand = 1\n",
    "            spp_module = PAPPM\n",
    "            dfm_module = LightBag\n",
    "            act_cfg_dfm = None\n",
    "        else:\n",
    "            self.d_branch_layers = nn.ModuleList([\n",
    "                self._make_single_layer(BasicBlock, channels * 2,\n",
    "                                        channels * 2),\n",
    "                self._make_single_layer(BasicBlock, channels * 2, channels * 2)\n",
    "            ])\n",
    "            channel_expand = 2\n",
    "            spp_module = DAPPM\n",
    "            dfm_module = Bag\n",
    "            act_cfg_dfm = act_cfg\n",
    "\n",
    "        self.diff_1 = ConvModule(\n",
    "            channels * 4,\n",
    "            channels * channel_expand,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=None)\n",
    "        self.diff_2 = ConvModule(\n",
    "            channels * 8,\n",
    "            channels * 2,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=None)\n",
    "\n",
    "        self.spp = spp_module(\n",
    "            channels * 16, ppm_channels, channels * 4, num_scales=5)\n",
    "        self.dfm = dfm_module(\n",
    "            channels * 4, channels * 4, norm_cfg=norm_cfg, act_cfg=act_cfg_dfm)\n",
    "\n",
    "        self.d_branch_layers.append(\n",
    "            self._make_layer(Bottleneck, channels * 2, channels * 2, 1))\n",
    "\n",
    "    def _make_stem_layer(self, in_channels: int, channels: int,\n",
    "                         num_blocks: int) -> nn.Sequential:\n",
    "        \"\"\"Make stem layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            channels (int): Number of output channels.\n",
    "            num_blocks (int): Number of blocks.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: The stem layer.\n",
    "        \"\"\"\n",
    "\n",
    "        layers = [\n",
    "            ConvModule(\n",
    "                in_channels,\n",
    "                channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg),\n",
    "            ConvModule(\n",
    "                channels,\n",
    "                channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg)\n",
    "        ]\n",
    "\n",
    "        layers.append(\n",
    "            self._make_layer(BasicBlock, channels, channels, num_blocks))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(\n",
    "            self._make_layer(\n",
    "                BasicBlock, channels, channels * 2, num_blocks, stride=2))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_layer(self,\n",
    "                    block: BasicBlock,\n",
    "                    in_channels: int,\n",
    "                    channels: int,\n",
    "                    num_blocks: int,\n",
    "                    stride: int = 1) -> nn.Sequential:\n",
    "        \"\"\"Make layer for PIDNet backbone.\n",
    "        Args:\n",
    "            block (BasicBlock): Basic block.\n",
    "            in_channels (int): Number of input channels.\n",
    "            channels (int): Number of output channels.\n",
    "            num_blocks (int): Number of blocks.\n",
    "            stride (int): Stride of the first block. Default: 1.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: The Branch Layer.\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != channels * block.expansion:\n",
    "            downsample = ConvModule(\n",
    "                in_channels,\n",
    "                channels * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=None)\n",
    "\n",
    "        layers = [block(in_channels, channels, stride, downsample)]\n",
    "        in_channels = channels * block.expansion\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    in_channels,\n",
    "                    channels,\n",
    "                    stride=1,\n",
    "                    act_cfg_out=None if i == num_blocks - 1 else self.act_cfg))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_single_layer(self,\n",
    "                           block: Union[BasicBlock, Bottleneck],\n",
    "                           in_channels: int,\n",
    "                           channels: int,\n",
    "                           stride: int = 1) -> nn.Module:\n",
    "        \"\"\"Make single layer for PIDNet backbone.\n",
    "        Args:\n",
    "            block (BasicBlock or Bottleneck): Basic block or Bottleneck.\n",
    "            in_channels (int): Number of input channels.\n",
    "            channels (int): Number of output channels.\n",
    "            stride (int): Stride of the first block. Default: 1.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module\n",
    "        \"\"\"\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != channels * block.expansion:\n",
    "            downsample = ConvModule(\n",
    "                in_channels,\n",
    "                channels * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=None)\n",
    "        return block(\n",
    "            in_channels, channels, stride, downsample, act_cfg_out=None)\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize the weights in backbone.\n",
    "\n",
    "        Since the D branch is not initialized by the pre-trained model, we\n",
    "        initialize it with the same method as the ResNet.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if self.init_cfg is not None:\n",
    "            assert 'checkpoint' in self.init_cfg, f'Only support ' \\\n",
    "                                                  f'specify `Pretrained` in ' \\\n",
    "                                                  f'`init_cfg` in ' \\\n",
    "                                                  f'{self.__class__.__name__} '\n",
    "            ckpt = CheckpointLoader.load_checkpoint(\n",
    "                self.init_cfg['checkpoint'], map_location='cpu')\n",
    "            self.load_state_dict(ckpt, strict=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Union[Tensor, Tuple[Tensor]]:\n",
    "        \"\"\"Forward function.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor with shape (B, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            Tensor or tuple[Tensor]: If self.training is True, return\n",
    "                tuple[Tensor], else return Tensor.\n",
    "        \"\"\"\n",
    "        w_out = x.shape[-1] // 8\n",
    "        h_out = x.shape[-2] // 8\n",
    "\n",
    "        # stage 0-2\n",
    "        x = self.stem(x)\n",
    "\n",
    "        # stage 3\n",
    "        x_i = self.relu(self.i_branch_layers[0](x))\n",
    "        x_p = self.p_branch_layers[0](x)\n",
    "        x_d = self.d_branch_layers[0](x)\n",
    "\n",
    "        comp_i = self.compression_1(x_i)\n",
    "        x_p = self.pag_1(x_p, comp_i)\n",
    "        diff_i = self.diff_1(x_i)\n",
    "        x_d += F.interpolate(\n",
    "            diff_i,\n",
    "            size=x_d.shape[2:],\n",
    "            mode='bilinear',\n",
    "            align_corners=self.align_corners)\n",
    "        if self.training:\n",
    "            temp_p = x_p.clone()\n",
    "\n",
    "        # stage 4\n",
    "        x_i = self.relu(self.i_branch_layers[1](x_i))\n",
    "        x_p = self.p_branch_layers[1](self.relu(x_p))\n",
    "        x_d = self.d_branch_layers[1](self.relu(x_d))\n",
    "\n",
    "        comp_i = self.compression_2(x_i)\n",
    "        x_p = self.pag_2(x_p, comp_i)\n",
    "        diff_i = self.diff_2(x_i)\n",
    "        x_d += F.interpolate(\n",
    "            diff_i,\n",
    "            size=x_d.shape[2:],\n",
    "            mode='bilinear',\n",
    "            align_corners=self.align_corners)\n",
    "        if self.training:\n",
    "            temp_d = x_d.clone()\n",
    "\n",
    "        # stage 5\n",
    "        x_i = self.i_branch_layers[2](x_i)\n",
    "        x_p = self.p_branch_layers[2](self.relu(x_p))\n",
    "        x_d = self.d_branch_layers[2](self.relu(x_d))\n",
    "\n",
    "        x_i = self.spp(x_i)\n",
    "        x_i = F.interpolate(\n",
    "            x_i,\n",
    "            size=x_d.shape[2:],\n",
    "            mode='bilinear',\n",
    "            align_corners=self.align_corners)\n",
    "        out = self.dfm(x_p, x_i, x_d)\n",
    "        return (temp_p, out, temp_d) if self.training else out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d81ba465",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:31.274272Z",
     "iopub.status.busy": "2023-05-11T10:19:31.273504Z",
     "iopub.status.idle": "2023-05-11T10:19:31.281564Z",
     "shell.execute_reply": "2023-05-11T10:19:31.280570Z"
    },
    "papermill": {
     "duration": 0.090089,
     "end_time": "2023-05-11T10:19:31.283507",
     "exception": false,
     "start_time": "2023-05-11T10:19:31.193418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/config.py\n",
    "_base_ = [\n",
    "    '/kaggle/working/mmsegmentation/configs/_base_/datasets/isic_dataset.py',\n",
    "    '/kaggle/working/mmsegmentation/configs/_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "# The class_weight is borrowed from https://github.com/openseg-group/OCNet.pytorch/issues/14 # noqa\n",
    "# Licensed under the MIT License\n",
    "class_weight =[1.0, 1.0]\n",
    "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth'  # noqa\n",
    "crop_size = (1024, 1024)\n",
    "data_preprocessor = dict(\n",
    "    type='SegDataPreProcessor',\n",
    "    mean=[123.675, 116.28, 103.53],\n",
    "    std=[58.395, 57.12, 57.375],\n",
    "    bgr_to_rgb=True,\n",
    "    pad_val=0,\n",
    "    seg_pad_val=255,\n",
    "    size=crop_size)\n",
    "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "model = dict(\n",
    "    type='EncoderDecoder',\n",
    "    data_preprocessor=data_preprocessor,\n",
    "    backbone=dict(\n",
    "        type='PIDNet',\n",
    "        in_channels=3,\n",
    "        channels=32,\n",
    "        ppm_channels=96,\n",
    "        num_stem_blocks=2,\n",
    "        num_branch_blocks=3,\n",
    "        align_corners=False,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='ReLU', inplace=True),\n",
    "        init_cfg=dict(type='Pretrained', checkpoint=checkpoint_file)),\n",
    "    decode_head=dict(\n",
    "        type='PIDHead',\n",
    "        in_channels=128,\n",
    "        channels=128,\n",
    "        num_classes=2,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='ReLU', inplace=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=[\n",
    "            dict(\n",
    "                type='CrossEntropyLoss',\n",
    "                use_sigmoid=False,\n",
    "                class_weight=class_weight,\n",
    "                loss_weight=0.4),\n",
    "            dict(\n",
    "                type='OhemCrossEntropy',\n",
    "                thres=0.9,\n",
    "                min_kept=131072,\n",
    "                class_weight=class_weight,\n",
    "                loss_weight=1.0),\n",
    "            dict(type='BoundaryLoss', loss_weight=20.0),\n",
    "            dict(\n",
    "                type='OhemCrossEntropy',\n",
    "                thres=0.9,\n",
    "                min_kept=131072,\n",
    "                class_weight=class_weight,\n",
    "                loss_weight=1.0)\n",
    "        ]),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode='whole'))\n",
    "\n",
    "iters = 1500\n",
    "# optimizer\n",
    "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer, clip_grad=None)\n",
    "# learning policy\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='PolyLR',\n",
    "        eta_min=0,\n",
    "        power=0.9,\n",
    "        begin=0,\n",
    "        end=iters,\n",
    "        by_epoch=False)\n",
    "]\n",
    "# training schedule for 10000\n",
    "train_cfg = dict(\n",
    "    type='IterBasedTrainLoop', max_iters=iters, val_interval=iters) \n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook', by_epoch=False, interval=iters), \n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='SegVisualizationHook'))\n",
    "\n",
    "randomness = dict(seed=304)\n",
    "work_dir = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69616990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:31.444093Z",
     "iopub.status.busy": "2023-05-11T10:19:31.443638Z",
     "iopub.status.idle": "2023-05-11T10:19:31.475260Z",
     "shell.execute_reply": "2023-05-11T10:19:31.474391Z"
    },
    "papermill": {
     "duration": 0.114607,
     "end_time": "2023-05-11T10:19:31.477629",
     "exception": false,
     "start_time": "2023-05-11T10:19:31.363022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmengine.config import Config, DictAction\n",
    "cfg = Config.fromfile('/kaggle/working/config.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9b8f3a4",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:31.640055Z",
     "iopub.status.busy": "2023-05-11T10:19:31.639228Z",
     "iopub.status.idle": "2023-05-11T10:19:40.993214Z",
     "shell.execute_reply": "2023-05-11T10:19:40.992255Z"
    },
    "papermill": {
     "duration": 9.437578,
     "end_time": "2023-05-11T10:19:40.995895",
     "exception": false,
     "start_time": "2023-05-11T10:19:31.558317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 304\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /opt/conda\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.0+cu113\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.1\n",
      "    OpenCV: 4.5.4\n",
      "    MMEngine: 0.7.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 304\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "dataset_type = 'ISICDataset'\n",
      "data_root = '/kaggle/input/isic-2018/data'\n",
      "img_scale = (2048, 1024)\n",
      "crop_size = (1024, 1024)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='ConvertPixel'),\n",
      "    dict(\n",
      "        type='RandomResize',\n",
      "        scale=(2048, 1024),\n",
      "        ratio_range=(0.5, 2.0),\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='GenerateEdge', edge_width=4),\n",
      "    dict(type='PackSegInputs')\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='ConvertPixel'),\n",
      "    dict(type='PackSegInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='ConvertPixel'),\n",
      "    dict(type='PackSegInputs')\n",
      "]\n",
      "img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]\n",
      "tta_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(\n",
      "        type='TestTimeAug',\n",
      "        transforms=[[{\n",
      "            'type': 'Resize',\n",
      "            'scale_factor': 0.5,\n",
      "            'keep_ratio': True\n",
      "        }, {\n",
      "            'type': 'Resize',\n",
      "            'scale_factor': 0.75,\n",
      "            'keep_ratio': True\n",
      "        }, {\n",
      "            'type': 'Resize',\n",
      "            'scale_factor': 1.0,\n",
      "            'keep_ratio': True\n",
      "        }, {\n",
      "            'type': 'Resize',\n",
      "            'scale_factor': 1.25,\n",
      "            'keep_ratio': True\n",
      "        }, {\n",
      "            'type': 'Resize',\n",
      "            'scale_factor': 1.5,\n",
      "            'keep_ratio': True\n",
      "        }, {\n",
      "            'type': 'Resize',\n",
      "            'scale_factor': 1.75,\n",
      "            'keep_ratio': True\n",
      "        }],\n",
      "                    [{\n",
      "                        'type': 'RandomFlip',\n",
      "                        'prob': 0.0,\n",
      "                        'direction': 'horizontal'\n",
      "                    }, {\n",
      "                        'type': 'RandomFlip',\n",
      "                        'prob': 1.0,\n",
      "                        'direction': 'horizontal'\n",
      "                    }], [{\n",
      "                        'type': 'LoadAnnotations'\n",
      "                    }], [{\n",
      "                        'type': 'PackSegInputs'\n",
      "                    }]])\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
      "    dataset=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=40000,\n",
      "        dataset=dict(\n",
      "            type='ISICDataset',\n",
      "            data_root='/kaggle/input/isic-2018/data',\n",
      "            data_prefix=dict(\n",
      "                img_path='images/train', seg_map_path='annotations/train'),\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(type='ConvertPixel'),\n",
      "                dict(\n",
      "                    type='RandomResize',\n",
      "                    scale=(2048, 1024),\n",
      "                    ratio_range=(0.5, 2.0),\n",
      "                    keep_ratio=True),\n",
      "                dict(\n",
      "                    type='RandomCrop',\n",
      "                    crop_size=(512, 512),\n",
      "                    cat_max_ratio=0.75),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(type='PhotoMetricDistortion'),\n",
      "                dict(type='GenerateEdge', edge_width=4),\n",
      "                dict(type='PackSegInputs')\n",
      "            ])))\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='ISICDataset',\n",
      "        data_root='/kaggle/input/isic-2018/data',\n",
      "        data_prefix=dict(\n",
      "            img_path='images/val', seg_map_path='annotations/val'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='ConvertPixel'),\n",
      "            dict(type='PackSegInputs')\n",
      "        ]))\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='ISICDataset',\n",
      "        data_root='/kaggle/input/isic-2018/data',\n",
      "        data_prefix=dict(\n",
      "            img_path='images/test', seg_map_path='annotations/test'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='ConvertPixel'),\n",
      "            dict(type='PackSegInputs')\n",
      "        ]))\n",
      "val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])\n",
      "test_evaluator = dict(\n",
      "    type='IoUMetric',\n",
      "    iou_metrics=['mIoU'],\n",
      "    format_only=True,\n",
      "    keep_results=True,\n",
      "    output_dir='/kaggle/working/test')\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[dict(type='LocalVisBackend')],\n",
      "    name='visualizer')\n",
      "log_processor = dict(by_epoch=False)\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "class_weight = [1.0, 1.0]\n",
      "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth'\n",
      "data_preprocessor = dict(\n",
      "    type='SegDataPreProcessor',\n",
      "    mean=[123.675, 116.28, 103.53],\n",
      "    std=[58.395, 57.12, 57.375],\n",
      "    bgr_to_rgb=True,\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(1024, 1024))\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    data_preprocessor=dict(\n",
      "        type='SegDataPreProcessor',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        bgr_to_rgb=True,\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(1024, 1024)),\n",
      "    backbone=dict(\n",
      "        type='PIDNet',\n",
      "        in_channels=3,\n",
      "        channels=32,\n",
      "        ppm_channels=96,\n",
      "        num_stem_blocks=2,\n",
      "        num_branch_blocks=3,\n",
      "        align_corners=False,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        act_cfg=dict(type='ReLU', inplace=True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth'\n",
      "        )),\n",
      "    decode_head=dict(\n",
      "        type='PIDHead',\n",
      "        in_channels=128,\n",
      "        channels=128,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        act_cfg=dict(type='ReLU', inplace=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=[\n",
      "            dict(\n",
      "                type='CrossEntropyLoss',\n",
      "                use_sigmoid=False,\n",
      "                class_weight=[1.0, 1.0],\n",
      "                loss_weight=0.4),\n",
      "            dict(\n",
      "                type='OhemCrossEntropy',\n",
      "                thres=0.9,\n",
      "                min_kept=131072,\n",
      "                class_weight=[1.0, 1.0],\n",
      "                loss_weight=1.0),\n",
      "            dict(type='BoundaryLoss', loss_weight=20.0),\n",
      "            dict(\n",
      "                type='OhemCrossEntropy',\n",
      "                thres=0.9,\n",
      "                min_kept=131072,\n",
      "                class_weight=[1.0, 1.0],\n",
      "                loss_weight=1.0)\n",
      "        ]),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "iters = 1500\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005),\n",
      "    clip_grad=None)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='PolyLR', eta_min=0, power=0.9, begin=0, end=1500, by_epoch=False)\n",
      "]\n",
      "train_cfg = dict(type='IterBasedTrainLoop', max_iters=1500, val_interval=1500)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval=1500),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "randomness = dict(seed=304)\n",
      "work_dir = '/kaggle/working/'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/kaggle/working/mmsegmentation/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "/kaggle/working/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/kaggle/working/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/11 10:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec6f3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:19:41.158103Z",
     "iopub.status.busy": "2023-05-11T10:19:41.157775Z",
     "iopub.status.idle": "2023-05-11T10:43:30.462166Z",
     "shell.execute_reply": "2023-05-11T10:43:30.460763Z"
    },
    "papermill": {
     "duration": 1429.429957,
     "end_time": "2023-05-11T10:43:30.506574",
     "exception": false,
     "start_time": "2023-05-11T10:19:41.076617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:20:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "05/11 10:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth\" to /root/.cache/torch/hub/checkpoints/pidnet-s_imagenet1k_20230306-715e6273.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:20:11 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "05/11 10:20:11 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "05/11 10:20:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working.\n",
      "05/11 10:21:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  50/1500]  lr: 9.7053e-03  eta: 0:27:40  time: 1.5389  data_time: 1.2797  memory: 10793  loss: 1.9240  decode.loss_sem_p: 0.1300  decode.loss_sem_i: 0.8174  decode.loss_bd: 0.1334  decode.loss_sem_bd: 0.8432  decode.acc_seg: 58.4813\n",
      "05/11 10:21:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 100/1500]  lr: 9.4036e-03  eta: 0:24:02  time: 1.1438  data_time: 0.8682  memory: 2887  loss: 1.3212  decode.loss_sem_p: 0.0474  decode.loss_sem_i: 0.4989  decode.loss_bd: 0.1116  decode.loss_sem_bd: 0.6633  decode.acc_seg: 88.0873\n",
      "05/11 10:22:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 150/1500]  lr: 9.1008e-03  eta: 0:21:40  time: 0.8204  data_time: 0.5407  memory: 2889  loss: 1.4577  decode.loss_sem_p: 0.0569  decode.loss_sem_i: 0.6560  decode.loss_bd: 0.1266  decode.loss_sem_bd: 0.6183  decode.acc_seg: 79.4621\n",
      "05/11 10:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 200/1500]  lr: 8.7969e-03  eta: 0:20:16  time: 0.7208  data_time: 0.4246  memory: 2887  loss: 1.3345  decode.loss_sem_p: 0.0622  decode.loss_sem_i: 0.5733  decode.loss_bd: 0.1147  decode.loss_sem_bd: 0.5842  decode.acc_seg: 71.4406\n",
      "05/11 10:24:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 250/1500]  lr: 8.4918e-03  eta: 0:19:13  time: 0.5737  data_time: 0.3224  memory: 2887  loss: 1.3916  decode.loss_sem_p: 0.0532  decode.loss_sem_i: 0.6210  decode.loss_bd: 0.1008  decode.loss_sem_bd: 0.6167  decode.acc_seg: 90.4099\n",
      "05/11 10:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 300/1500]  lr: 8.1854e-03  eta: 0:18:31  time: 1.0140  data_time: 0.7566  memory: 2887  loss: 1.3834  decode.loss_sem_p: 0.0506  decode.loss_sem_i: 0.5787  decode.loss_bd: 0.1148  decode.loss_sem_bd: 0.6393  decode.acc_seg: 76.5464\n",
      "05/11 10:25:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 350/1500]  lr: 7.8778e-03  eta: 0:17:57  time: 1.3397  data_time: 1.0847  memory: 2887  loss: 1.2206  decode.loss_sem_p: 0.0459  decode.loss_sem_i: 0.4659  decode.loss_bd: 0.1045  decode.loss_sem_bd: 0.6044  decode.acc_seg: 60.7961\n",
      "05/11 10:26:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 400/1500]  lr: 7.5689e-03  eta: 0:17:15  time: 1.1175  data_time: 0.8238  memory: 2887  loss: 1.4110  decode.loss_sem_p: 0.0617  decode.loss_sem_i: 0.5681  decode.loss_bd: 0.1054  decode.loss_sem_bd: 0.6758  decode.acc_seg: 92.1258\n",
      "05/11 10:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 450/1500]  lr: 7.2585e-03  eta: 0:16:37  time: 1.0449  data_time: 0.7547  memory: 2888  loss: 1.2732  decode.loss_sem_p: 0.0536  decode.loss_sem_i: 0.5702  decode.loss_bd: 0.1147  decode.loss_sem_bd: 0.5347  decode.acc_seg: 72.2656\n",
      "05/11 10:28:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 500/1500]  lr: 6.9467e-03  eta: 0:15:49  time: 0.8710  data_time: 0.6134  memory: 2888  loss: 1.3911  decode.loss_sem_p: 0.0560  decode.loss_sem_i: 0.5564  decode.loss_bd: 0.1090  decode.loss_sem_bd: 0.6697  decode.acc_seg: 92.6888\n",
      "05/11 10:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 550/1500]  lr: 6.6333e-03  eta: 0:14:52  time: 0.9981  data_time: 0.7179  memory: 2887  loss: 1.3827  decode.loss_sem_p: 0.0459  decode.loss_sem_i: 0.5481  decode.loss_bd: 0.1472  decode.loss_sem_bd: 0.6415  decode.acc_seg: 90.6374\n",
      "05/11 10:29:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 600/1500]  lr: 6.3182e-03  eta: 0:13:59  time: 1.1223  data_time: 0.8740  memory: 2888  loss: 1.3092  decode.loss_sem_p: 0.0518  decode.loss_sem_i: 0.5321  decode.loss_bd: 0.1186  decode.loss_sem_bd: 0.6067  decode.acc_seg: 89.0595\n",
      "05/11 10:30:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 650/1500]  lr: 6.0014e-03  eta: 0:13:10  time: 1.1246  data_time: 0.8535  memory: 2887  loss: 1.2642  decode.loss_sem_p: 0.0527  decode.loss_sem_i: 0.5163  decode.loss_bd: 0.1132  decode.loss_sem_bd: 0.5820  decode.acc_seg: 76.8352\n",
      "05/11 10:30:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 700/1500]  lr: 5.6828e-03  eta: 0:12:15  time: 0.6413  data_time: 0.3755  memory: 2888  loss: 1.2039  decode.loss_sem_p: 0.0516  decode.loss_sem_i: 0.5155  decode.loss_bd: 0.1026  decode.loss_sem_bd: 0.5341  decode.acc_seg: 87.1819\n",
      "05/11 10:31:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 750/1500]  lr: 5.3621e-03  eta: 0:11:29  time: 1.0014  data_time: 0.7355  memory: 2889  loss: 1.3470  decode.loss_sem_p: 0.0521  decode.loss_sem_i: 0.5748  decode.loss_bd: 0.1230  decode.loss_sem_bd: 0.5970  decode.acc_seg: 64.3187\n",
      "05/11 10:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 800/1500]  lr: 5.0393e-03  eta: 0:10:48  time: 1.1704  data_time: 0.9155  memory: 2888  loss: 1.1624  decode.loss_sem_p: 0.0492  decode.loss_sem_i: 0.5509  decode.loss_bd: 0.1108  decode.loss_sem_bd: 0.4515  decode.acc_seg: 85.0996\n",
      "05/11 10:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 850/1500]  lr: 4.7141e-03  eta: 0:09:59  time: 1.0338  data_time: 0.7690  memory: 2887  loss: 1.1653  decode.loss_sem_p: 0.0503  decode.loss_sem_i: 0.4709  decode.loss_bd: 0.1052  decode.loss_sem_bd: 0.5389  decode.acc_seg: 86.2794\n",
      "05/11 10:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 900/1500]  lr: 4.3865e-03  eta: 0:09:12  time: 0.7541  data_time: 0.4491  memory: 2887  loss: 1.1642  decode.loss_sem_p: 0.0473  decode.loss_sem_i: 0.4689  decode.loss_bd: 0.1130  decode.loss_sem_bd: 0.5350  decode.acc_seg: 84.2569\n",
      "05/11 10:34:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 950/1500]  lr: 4.0561e-03  eta: 0:08:26  time: 0.9649  data_time: 0.7001  memory: 2888  loss: 1.2325  decode.loss_sem_p: 0.0526  decode.loss_sem_i: 0.4327  decode.loss_bd: 0.1178  decode.loss_sem_bd: 0.6294  decode.acc_seg: 90.3959\n",
      "05/11 10:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230511_101932\n",
      "05/11 10:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1000/1500]  lr: 3.7226e-03  eta: 0:07:40  time: 1.0250  data_time: 0.7551  memory: 2888  loss: 1.1076  decode.loss_sem_p: 0.0414  decode.loss_sem_i: 0.4192  decode.loss_bd: 0.1112  decode.loss_sem_bd: 0.5358  decode.acc_seg: 85.6007\n",
      "05/11 10:36:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1050/1500]  lr: 3.3859e-03  eta: 0:06:51  time: 0.8263  data_time: 0.5692  memory: 2890  loss: 1.0250  decode.loss_sem_p: 0.0389  decode.loss_sem_i: 0.4696  decode.loss_bd: 0.0946  decode.loss_sem_bd: 0.4219  decode.acc_seg: 93.5419\n",
      "05/11 10:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1100/1500]  lr: 3.0453e-03  eta: 0:06:06  time: 0.8943  data_time: 0.6331  memory: 2888  loss: 1.2611  decode.loss_sem_p: 0.0543  decode.loss_sem_i: 0.5099  decode.loss_bd: 0.1073  decode.loss_sem_bd: 0.5896  decode.acc_seg: 60.5745\n",
      "05/11 10:37:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1150/1500]  lr: 2.7005e-03  eta: 0:05:19  time: 0.7787  data_time: 0.4581  memory: 2887  loss: 1.3226  decode.loss_sem_p: 0.0596  decode.loss_sem_i: 0.5684  decode.loss_bd: 0.1111  decode.loss_sem_bd: 0.5834  decode.acc_seg: 89.6261\n",
      "05/11 10:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1200/1500]  lr: 2.3506e-03  eta: 0:04:33  time: 0.7919  data_time: 0.5406  memory: 2887  loss: 1.1636  decode.loss_sem_p: 0.0578  decode.loss_sem_i: 0.5876  decode.loss_bd: 0.1129  decode.loss_sem_bd: 0.4053  decode.acc_seg: 67.9706\n",
      "05/11 10:39:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1250/1500]  lr: 1.9949e-03  eta: 0:03:47  time: 1.2324  data_time: 0.9735  memory: 2888  loss: 1.1026  decode.loss_sem_p: 0.0503  decode.loss_sem_i: 0.4721  decode.loss_bd: 0.1169  decode.loss_sem_bd: 0.4633  decode.acc_seg: 72.0335\n",
      "05/11 10:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1300/1500]  lr: 1.6319e-03  eta: 0:03:01  time: 0.7209  data_time: 0.4555  memory: 2887  loss: 1.1252  decode.loss_sem_p: 0.0431  decode.loss_sem_i: 0.4396  decode.loss_bd: 0.1047  decode.loss_sem_bd: 0.5378  decode.acc_seg: 96.9604\n",
      "05/11 10:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1350/1500]  lr: 1.2597e-03  eta: 0:02:16  time: 0.6841  data_time: 0.4406  memory: 2888  loss: 1.3067  decode.loss_sem_p: 0.0523  decode.loss_sem_i: 0.5774  decode.loss_bd: 0.0950  decode.loss_sem_bd: 0.5820  decode.acc_seg: 85.4807\n",
      "05/11 10:41:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1400/1500]  lr: 8.7454e-04  eta: 0:01:30  time: 1.2003  data_time: 0.9201  memory: 2888  loss: 1.2108  decode.loss_sem_p: 0.0482  decode.loss_sem_i: 0.5168  decode.loss_bd: 0.1135  decode.loss_sem_bd: 0.5323  decode.acc_seg: 91.5607\n",
      "05/11 10:42:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1450/1500]  lr: 4.6865e-04  eta: 0:00:45  time: 1.2253  data_time: 0.9419  memory: 2888  loss: 1.2652  decode.loss_sem_p: 0.0489  decode.loss_sem_i: 0.4605  decode.loss_bd: 0.1045  decode.loss_sem_bd: 0.6512  decode.acc_seg: 83.6639\n",
      "05/11 10:42:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [1500/1500]  lr: 0.0000e+00  eta: 0:00:00  time: 0.5994  data_time: 0.2948  memory: 2888  loss: 1.0749  decode.loss_sem_p: 0.0454  decode.loss_sem_i: 0.4632  decode.loss_bd: 0.1017  decode.loss_sem_bd: 0.4646  decode.acc_seg: 91.3675\n",
      "05/11 10:42:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1500 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:43:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:17  time: 0.0999  data_time: 0.0213  memory: 8735  \n",
      "05/11 10:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.1672  data_time: 0.0136  memory: 8526  \n",
      "05/11 10:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/11 10:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 82.39 | 89.87 |\n",
      "|    mask    | 55.26 | 72.31 |\n",
      "+------------+-------+-------+\n",
      "05/11 10:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 85.5300  mIoU: 68.8200  mAcc: 81.0900  data_time: 0.0481  time: 0.2948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (data_preprocessor): SegDataPreProcessor()\n",
       "  (backbone): PIDNet(\n",
       "    (stem): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (i_branch_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): ConvModule(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): ConvModule(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p_branch_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (compression_1): ConvModule(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (compression_2): ConvModule(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pag_1): PagFM(\n",
       "      (f_i): ConvModule(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (f_p): ConvModule(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pag_2): PagFM(\n",
       "      (f_i): ConvModule(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (f_p): ConvModule(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (d_branch_layers): ModuleList(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): ConvModule(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvModule(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (downsample): ConvModule(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (diff_1): ConvModule(\n",
       "      (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (diff_2): ConvModule(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (spp): PAPPM(\n",
       "      (scales): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=5, stride=2, padding=2)\n",
       "          (1): ConvModule(\n",
       "            (conv): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=9, stride=4, padding=4)\n",
       "          (1): ConvModule(\n",
       "            (conv): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=17, stride=8, padding=8)\n",
       "          (1): ConvModule(\n",
       "            (conv): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "          (1): ConvModule(\n",
       "            (conv): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (processes): ConvModule(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (compression): ConvModule(\n",
       "        (conv): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (shortcut): ConvModule(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dfm): LightBag(\n",
       "      (f_p): ConvModule(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (f_i): ConvModule(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/pidnet/pidnet-s_imagenet1k_20230306-715e6273.pth'}\n",
       "  (decode_head): PIDHead(\n",
       "    input_transform=None, ignore_index=255, align_corners=False\n",
       "    (loss_decode): ModuleList(\n",
       "      (0): CrossEntropyLoss(avg_non_ignore=False)\n",
       "      (1): OhemCrossEntropy()\n",
       "      (2): BoundaryLoss()\n",
       "      (3): OhemCrossEntropy()\n",
       "    )\n",
       "    (conv_seg): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (i_head): BasePIDHead(\n",
       "      (conv): ConvModule(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (norm): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (p_head): BasePIDHead(\n",
       "      (conv): ConvModule(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (norm): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (d_head): BasePIDHead(\n",
       "      (conv): ConvModule(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (norm): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (p_cls_seg): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (d_cls_seg): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69506cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T10:43:30.680212Z",
     "iopub.status.busy": "2023-05-11T10:43:30.679838Z",
     "iopub.status.idle": "2023-05-11T10:49:19.653901Z",
     "shell.execute_reply": "2023-05-11T10:49:19.652797Z"
    },
    "papermill": {
     "duration": 349.064568,
     "end_time": "2023-05-11T10:49:19.657833",
     "exception": false,
     "start_time": "2023-05-11T10:43:30.593265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 10:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [  50/1000]    eta: 0:10:44  time: 1.4842  data_time: 0.0767  memory: 801  \n",
      "05/11 10:45:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 100/1000]    eta: 0:16:01  time: 1.3933  data_time: 0.0640  memory: 8742  \n",
      "05/11 10:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 150/1000]    eta: 0:13:15  time: 0.0344  data_time: 0.0038  memory: 805  \n",
      "05/11 10:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 200/1000]    eta: 0:09:28  time: 0.0371  data_time: 0.0043  memory: 200  \n",
      "05/11 10:45:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 250/1000]    eta: 0:07:12  time: 0.0369  data_time: 0.0037  memory: 200  \n",
      "05/11 10:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 300/1000]    eta: 0:05:40  time: 0.0370  data_time: 0.0037  memory: 200  \n",
      "05/11 10:46:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 350/1000]    eta: 0:04:35  time: 0.0668  data_time: 0.0089  memory: 200  \n",
      "05/11 10:46:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 400/1000]    eta: 0:03:45  time: 0.0369  data_time: 0.0041  memory: 200  \n",
      "05/11 10:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 450/1000]    eta: 0:03:14  time: 0.3862  data_time: 0.0164  memory: 8514  \n",
      "05/11 10:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 500/1000]    eta: 0:02:57  time: 0.4108  data_time: 0.0137  memory: 8541  \n",
      "05/11 10:46:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 550/1000]    eta: 0:02:41  time: 0.2819  data_time: 0.0180  memory: 8557  \n",
      "05/11 10:47:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 600/1000]    eta: 0:02:21  time: 0.3277  data_time: 0.0189  memory: 279  \n",
      "05/11 10:47:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 650/1000]    eta: 0:02:02  time: 0.2662  data_time: 0.0184  memory: 8564  \n",
      "05/11 10:47:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 700/1000]    eta: 0:01:46  time: 0.4145  data_time: 0.0255  memory: 8584  \n",
      "05/11 10:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 750/1000]    eta: 0:01:29  time: 0.2785  data_time: 0.0149  memory: 8546  \n",
      "05/11 10:48:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 800/1000]    eta: 0:01:11  time: 0.3043  data_time: 0.0171  memory: 8508  \n",
      "05/11 10:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 850/1000]    eta: 0:00:52  time: 0.3084  data_time: 0.0196  memory: 279  \n",
      "05/11 10:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 900/1000]    eta: 0:00:35  time: 0.3033  data_time: 0.0190  memory: 279  \n",
      "05/11 10:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 950/1000]    eta: 0:00:17  time: 0.2794  data_time: 0.0127  memory: 8540  \n",
      "05/11 10:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [1000/1000]    eta: 0:00:00  time: 0.2426  data_time: 0.0108  memory: 8560  \n",
      "05/11 10:49:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - IoUMetric got empty `self.results`. Please ensure that the processed results are properly added into `self.results` in `process` method.\n",
      "05/11 10:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - results are saved to /kaggle/working\n",
      "05/11 10:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [1000/1000]    data_time: 0.0210  time: 0.3451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1992.277204,
   "end_time": "2023-05-11T10:49:22.888790",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-11T10:16:10.611586",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
